{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNU1xBiDIxJLr3TAyutbymJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zbreeden/trainer-model/blob/main/Glossary_Merge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "E2QKJzCwhx3G",
        "outputId": "e17fe0fc-6c4d-4543-cc7e-6a9c55c17f0b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Mountpoint must be in a directory that exists",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1045918145.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/MyDrive/FourTwentyAnalytics/modules/trainer-model/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mnormed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must be in a directory that exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m   \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_signal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGKILL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must be in a directory that exists"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/MyDrive/FourTwentyAnalytics/modules/trainer-model/')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f935cb6",
        "outputId": "ec95db34-1b8e-496c-e854-7dfce7ce8c30"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "mountpoint = '/MyDrive/FourTwentyAnalytics/modules/trainer-model/'\n",
        "os.makedirs(mountpoint, exist_ok=True)\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount(mountpoint)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /MyDrive/FourTwentyAnalytics/modules/trainer-model/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "352d605d",
        "outputId": "97b3219c-272d-44e3-c0f2-c21efbc4d8db"
      },
      "source": [
        "import os\n",
        "\n",
        "mountpoint = '/MyDrive/FourTwentyAnalytics/modules/trainer-model/'\n",
        "contents = os.listdir(mountpoint)\n",
        "print(contents)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['MyDrive', '.shortcut-targets-by-id', '.Trash-0', '.Encrypted']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2a9492f",
        "outputId": "0427bc7c-426f-4860-f345-35f99e0ee0f8"
      },
      "source": [
        "import os\n",
        "\n",
        "mountpoint = '/MyDrive/FourTwentyAnalytics/modules/trainer-model/'\n",
        "mydrive_path = os.path.join(mountpoint, 'MyDrive')\n",
        "contents_mydrive = os.listdir(mydrive_path)\n",
        "print(contents_mydrive)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Colab Notebooks', 'FourTwentyAnalytics', 'Getting started.pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7a05667",
        "outputId": "22ca089f-e06f-4919-8faa-7d82fb7e3363"
      },
      "source": [
        "import os\n",
        "\n",
        "mountpoint = '/MyDrive/FourTwentyAnalytics/modules/trainer-model/'\n",
        "fourtwentyanalytics_path = os.path.join(mountpoint, 'MyDrive', 'FourTwentyAnalytics')\n",
        "contents_fourtwentyanalytics = os.listdir(fourtwentyanalytics_path)\n",
        "print(contents_fourtwentyanalytics)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['seeds', 'modules']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24f8a015",
        "outputId": "caf5497c-787c-4f60-bbd4-3808f9fd811d"
      },
      "source": [
        "import os\n",
        "\n",
        "mountpoint = '/MyDrive/FourTwentyAnalytics/modules/trainer-model/'\n",
        "modules_path = os.path.join(mountpoint, 'MyDrive', 'FourTwentyAnalytics', 'modules')\n",
        "contents_modules = os.listdir(modules_path)\n",
        "print(contents_modules)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['trainer-model']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a2907b2",
        "outputId": "57ae609a-3137-4cb8-986f-f0355b8bf3f6"
      },
      "source": [
        "import os\n",
        "\n",
        "mountpoint = '/MyDrive/FourTwentyAnalytics/modules/trainer-model/'\n",
        "contents_trainer_model = os.listdir(mountpoint)\n",
        "print(contents_trainer_model)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['MyDrive', '.shortcut-targets-by-id', '.Trash-0', '.Encrypted']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Remount Google Drive\n",
        "# Use the same mountpoint as before\n",
        "mountpoint = '/MyDrive/FourTwentyAnalytics/modules/trainer-model/'\n",
        "# Ensure the directory exists before mounting\n",
        "os.makedirs(mountpoint, exist_ok=True)\n",
        "drive.mount(mountpoint)\n",
        "\n",
        "# Now attempt to upload the file\n",
        "uploaded = files.upload('/content/drive/MyDrive/FourTwentyAnalytics/modules/trainer-model/data/merge_map.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "e_BKYyHbr26C",
        "outputId": "2ba8668a-9ef5-48c0-f855-da65b8c98bec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /MyDrive/FourTwentyAnalytics/modules/trainer-model/; to attempt to forcibly remount, call drive.mount(\"/MyDrive/FourTwentyAnalytics/modules/trainer-model/\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6d3074c7-2276-4deb-bd67-ecf50c829b0b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6d3074c7-2276-4deb-bd67-ecf50c829b0b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[Errno 107] Transport endpoint is not connected: '/content/drive/MyDrive'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3167343541.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Now attempt to upload the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/FourTwentyAnalytics/modules/trainer-model/data/merge_map.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;31m# If there was a specified target directory, create it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected: '/content/drive/MyDrive'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e787f625",
        "outputId": "4620dfd3-e54b-4106-9359-e4d1fe98c9e4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6f323fc",
        "outputId": "0e12f3e0-4951-4afe-987c-835faa042eea"
      },
      "source": [
        "import os\n",
        "\n",
        "# Change the current working directory\n",
        "target_directory = '/content/drive/MyDrive/FourTwentyAnalytics/modules/trainer-model/'\n",
        "os.chdir(target_directory)\n",
        "\n",
        "# Verify the current working directory\n",
        "print(f\"Current working directory: {os.getcwd()}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content/drive/MyDrive/FourTwentyAnalytics/modules/trainer-model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, csv, shutil\n",
        "from typing import List, Dict, Any # Corrected import\n",
        "import yaml\n",
        "\n",
        "REQUIRED_FIELDS = {\"key\", \"term\", \"definition\"}\n",
        "LIST_FIELDS = {\"examples\", \"see_also\", \"tags\"}\n",
        "DICT_FIELDS = {\"source\"}\n",
        "\n",
        "def _non_empty(v): return v not in (None, \"\", [], {})\n",
        "def _merge_lists(a, b): return list(dict.fromkeys((a or []) + (b or [])))\n",
        "def _merge_dicts(a, b):\n",
        "    out = dict(a or {})\n",
        "    for k, v in (b or {}).items():\n",
        "        if k not in out or not _non_empty(out[k]):\n",
        "            out[k] = v\n",
        "    return out\n",
        "\n",
        "def _merge_entries(a: Dict[str, Any], b: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    if not a: return dict(b)\n",
        "    out = dict(a)\n",
        "    for k, bv in b.items():\n",
        "        av = out.get(k)\n",
        "        if k in LIST_FIELDS:\n",
        "            out[k] = _merge_lists(av, bv)\n",
        "        elif k in DICT_FIELDS:\n",
        "            out[k] = _merge_dicts(av, bv)\n",
        "        elif not _non_empty(av) and _non_empty(bv):\n",
        "            out[k] = bv\n",
        "    return out\n",
        "def _load_yaml_list(path: str):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = yaml.safe_load(f) or []\n",
        "    if not isinstance(data, list):\n",
        "        raise ValueError(f\"{path} must be a YAML list\")\n",
        "    for i, item in enumerate(data):\n",
        "        if not isinstance(item, dict):\n",
        "            raise ValueError(f\"{path} item {i+1} is not a mapping\")\n",
        "        missing = REQUIRED_FIELDS - set(item.keys())\n",
        "        if missing:\n",
        "            raise ValueError(f\"{path} item {i+1} missing: {', '.join(sorted(missing))}\")\n",
        "    return data\n",
        "\n",
        "def _write_yaml(path: str, items: List[Dict[str, Any]]):\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    if os.path.exists(path):\n",
        "        shutil.copy2(path, path + \".bak\")\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        yaml.safe_dump(items, f, sort_keys=False, allow_unicode=True, width=1000)\n",
        "\n",
        "def merge_glossaries(inputs: List[str], out: str = \"trainer-model/seeds/glossary.yml\", sort_by: str = \"key\", dry_run: bool = False):\n",
        "    merged: Dict[str, Dict[str, Any]] = {}\n",
        "    seen = 0\n",
        "    for p in inputs:\n",
        "        items = _load_yaml_list(p)\n",
        "        for e in items:\n",
        "            k = e[\"key\"]\n",
        "            merged[k] = _merge_entries(merged.get(k), e)\n",
        "            seen += 1\n",
        "    out_list = sorted(merged.values(), key=lambda d: (d.get(sort_by) or \"\").lower())\n",
        "    print(f\"[summary] files={len(inputs)} items_in={seen} unique={len(out_list)} deduped={seen-len(out_list)}\")\n",
        "    if not dry_run:\n",
        "        _write_yaml(out, out_list)\n",
        "        print(f\"[ok] wrote {out}\")\n",
        "    return out_list\n",
        "\n",
        "# Replace your existing merge_from_csv with this more robust version.\n",
        "import csv, os\n",
        "\n",
        "def merge_from_csv(csv_path: str,\n",
        "                   out: str = \"trainer-model/seeds/glossary.yml\",\n",
        "                   sort_by: str = \"key\",\n",
        "                   dry_run: bool = False):\n",
        "    \"\"\"\n",
        "    Reads a 2-col CSV and merges the YAML files listed in the first column.\n",
        "    Accepts headers like 'The_Trainer_Artifact' and 'Append_File' (case/space/BOM/underscore/hyphen tolerant).\n",
        "    Also auto-detects delimiter: , ; \\t |\n",
        "    \"\"\"\n",
        "\n",
        "    def _canon(s: str) -> str:\n",
        "        # normalize header names (strip BOM, NBSP, spaces, dashes)\n",
        "        return (s or \"\").replace(\"\\ufeff\", \"\").replace(\"\\u00a0\", \" \").strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
        "\n",
        "    # 1) Open with utf-8-sig to strip BOM; sniff delimiter.\n",
        "    with open(csv_path, \"r\", encoding=\"utf-8-sig\", newline=\"\") as f:\n",
        "        sample = f.read(4096)\n",
        "        f.seek(0)\n",
        "        try:\n",
        "            dialect = csv.Sniffer().sniff(sample, delimiters=\",;\\t|\")\n",
        "        except csv.Error:\n",
        "            dialect = csv.excel\n",
        "        rdr = csv.DictReader(f, dialect=dialect)\n",
        "        headers = rdr.fieldnames or []\n",
        "\n",
        "        # 2) Build a lookup from canonicalized → original header\n",
        "        canon_map = {_canon(h): h for h in headers}\n",
        "\n",
        "        # 3) Find the two columns, allowing a few synonyms\n",
        "        src_h = (canon_map.get(\"the_trainer_artifact\")\n",
        "                 or canon_map.get(\"artifact\")\n",
        "                 or canon_map.get(\"source\")\n",
        "                 or canon_map.get(\"input\"))\n",
        "        dst_h = (canon_map.get(\"append_file\")\n",
        "                 or canon_map.get(\"target\")\n",
        "                 or canon_map.get(\"out\")\n",
        "                 or canon_map.get(\"output\"))\n",
        "\n",
        "        if not src_h or not dst_h:\n",
        "            raise KeyError(\n",
        "                \"Required CSV headers not found.\\n\"\n",
        "                f\"Seen headers: {headers}\\n\"\n",
        "                \"Looking for 'The_Trainer_Artifact' and 'Append_File' (case/space/BOM tolerant).\"\n",
        "            )\n",
        "\n",
        "        # 4) Collect input YAML paths from the source column\n",
        "        inputs = []\n",
        "        for row in rdr:\n",
        "            p = (row.get(src_h) or \"\").strip()\n",
        "            if p:\n",
        "                inputs.append(p)\n",
        "\n",
        "    # 5) Reuse your existing merge_glossaries(...)\n",
        "    return merge_glossaries(inputs, out=out, sort_by=sort_by, dry_run=dry_run)\n"
      ],
      "metadata": {
        "id": "1EnasbqQvsjs"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base = \"/MyDrive/FourTwentyAnalytics/modules/trainer-model\"\n",
        "csv_path = f\"{base}/data/merge_map.csv\"\n",
        "out_path = f\"{base}/seeds/glossary.yml\""
      ],
      "metadata": {
        "id": "cBAxsQsVzYsl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"CSV exists:\", os.path.exists(csv_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjGCtYeV5OLf",
        "outputId": "4fe2073e-b36e-4913-d011-0b459b7265dc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV exists: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/FourTwentyAnalytics\"  # <- adjust if needed\n",
        "candidates = [\n",
        "    \"/content/merge_map.csv\",\n",
        "    \"/content/drive/MyDrive/merge_map.csv\",\n",
        "    f\"{BASE}/merge_map.csv\",\n",
        "]\n",
        "\n",
        "print(\"Drive mounted:\", os.path.exists(\"/content/drive/MyDrive\"))\n",
        "for p in candidates:\n",
        "    print(p, \"→\", os.path.exists(p))\n",
        "\n",
        "hits = glob(\"/content/drive/**/merge_map.csv\", recursive=True)\n",
        "print(\"Found in Drive:\", hits[:10])  # show first 10 matches\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQCnVt8K6yMq",
        "outputId": "d29c7feb-7d4e-40ad-9544-8288b9033617"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive mounted: True\n",
            "/content/merge_map.csv → False\n",
            "/content/drive/MyDrive/merge_map.csv → False\n",
            "/content/drive/MyDrive/FourTwentyAnalytics/merge_map.csv → False\n",
            "Found in Drive: ['/content/drive/MyDrive/FourTwentyAnalytics/modules/trainer-model/data/merge_map.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = \"/content/drive/MyDrive/FourTwentyAnalytics/modules/trainer-model/data/merge_map.csv\"\n",
        "merge_from_csv(csv_path, out=f\"{base}/seeds/glossary.yml\", dry_run=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "cPuXkdDY7RhX",
        "outputId": "fc32d40b-3ac0-472c-f6a7-02112eb3112a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'The_Trainer_Artifact'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-164868475.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcsv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/FourTwentyAnalytics/modules/trainer-model/data/merge_map.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmerge_from_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{base}/seeds/glossary.yml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-901562402.py\u001b[0m in \u001b[0;36mmerge_from_csv\u001b[0;34m(csv_path, out, sort_by, dry_run)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# expect columns: The_Trainer_Artifact, Append_File\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrdr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"The_Trainer_Artifact\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_glossaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_by\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'The_Trainer_Artifact'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE = \"/content/drive/MyDrive/FourTwentyAnalytics\"\n",
        "csv_path = f\"{BASE}/modules/trainer-model/data/merge_map.csv\"\n",
        "out_path = f\"{BASE}/modules/trainer-model/seeds/glossary.yml\"\n"
      ],
      "metadata": {
        "id": "T_3WB1J8_w7K"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"CSV exists:\", os.path.exists(csv_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVpUl7STBOA1",
        "outputId": "18dd6d1a-dd04-406b-b83b-4e817f37ffef"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merge_from_csv(csv_path, out=out_path, dry_run=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "YFHVfShMBbbt",
        "outputId": "b7f41e79-6092-4947-e46c-3864e22c98ab"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'The_Trainer_Artifact'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3437364156.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmerge_from_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-901562402.py\u001b[0m in \u001b[0;36mmerge_from_csv\u001b[0;34m(csv_path, out, sort_by, dry_run)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# expect columns: The_Trainer_Artifact, Append_File\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrdr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"The_Trainer_Artifact\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_glossaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_by\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'The_Trainer_Artifact'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = f\"{BASE}/modules/trainer-model/data/merge_map.csv\"\n",
        "merge_from_csv(csv_path, out=out_path, dry_run=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_tNASusB2WK",
        "outputId": "e7e1bf40-85cc-4ad6-c5b6-3f9988b0b4c3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[summary] files=5 items_in=88 unique=64 deduped=24\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'key': 'analyst-skills',\n",
              "  'term': 'Analyst Skills (Technical, Functional, Soft)',\n",
              "  'definition': 'Blend of tool proficiency (spreadsheets, SQL, viz tools, programming), functional capabilities (statistics, analytical thinking, problem-solving, probing, project management), and soft skills (collaboration, communication, storytelling, curiosity, informed intuition).\\n',\n",
              "  'examples': ['SQL for joins; Power BI dashboards; stakeholder workshop; narrative readout'],\n",
              "  'see_also': ['sql', 'data-visualization', 'statistics', 'storytelling'],\n",
              "  'tags': ['ibm', 'skills'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 1 – Skills'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'apache-spark',\n",
              "  'term': 'Apache Spark',\n",
              "  'definition': 'Distributed processing engine (batch & streaming) with in-memory acceleration and APIs for SQL, Python, R, Java/Scala.\\n',\n",
              "  'examples': ['Process engagement stream to compute rolling WIP/throughput'],\n",
              "  'see_also': ['hadoop', 'hdfs', 'data-streams'],\n",
              "  'tags': ['ibm', 'big-data', 'streaming'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Big Data Tools'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'babok-guide',\n",
              "  'term': 'BABOK Guide',\n",
              "  'definition': 'The Guide to the Business Analysis Body of Knowledge from IIBA that defines the profession and describes commonly accepted practices, knowledge areas, tasks, techniques, and underlying competencies.\\n',\n",
              "  'examples': ['Referencing BABOK when mapping The Trainer tasks to knowledge areas'],\n",
              "  'see_also': ['iiba', 'babok-knowledge-areas'],\n",
              "  'tags': ['cbap', 'standard'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'babok-knowledge-areas',\n",
              "  'term': 'BABOK Knowledge Areas',\n",
              "  'definition': 'Six domains that organize BA work: Business Analysis Planning & Monitoring; Elicitation & Collaboration; Requirements Life Cycle Management; Strategy Analysis; Requirements Analysis & Design Definition; and Solution Evaluation.\\n',\n",
              "  'examples': ['Tagging Trainer tasks with the relevant knowledge area'],\n",
              "  'see_also': ['elicitation',\n",
              "   'requirements-lifecycle-management',\n",
              "   'strategy-analysis',\n",
              "   'solution-evaluation'],\n",
              "  'tags': ['cbap', 'framework'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'baccm',\n",
              "  'term': 'Business Analysis Core Concept Model (BACCM)',\n",
              "  'definition': 'A shared mental framework for business analysis built on six equal concepts— Change, Need, Solution, Stakeholder, Value, and Context—used to frame any BA task regardless of domain or methodology.\\n',\n",
              "  'examples': ['Framing The Trainer: identify the Need, define the Change and Solution, map Stakeholders, value, and Context'],\n",
              "  'see_also': ['change',\n",
              "   'need',\n",
              "   'solution',\n",
              "   'stakeholder',\n",
              "   'value',\n",
              "   'context',\n",
              "   'babok-guide'],\n",
              "  'tags': ['cbap', 'framework'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 2 – BACCM & Techniques'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'bi-analyst',\n",
              "  'term': 'Business Intelligence (BI) Analyst',\n",
              "  'definition': 'Organizes and monitors business data, builds standardized reports/dashboards, and explores trends to support performance decisions, often with market/external focus.\\n',\n",
              "  'examples': ['Power BI sales dashboard with daily refresh and drill-downs'],\n",
              "  'see_also': ['data-analyst', 'kpi', 'dashboard'],\n",
              "  'tags': ['ibm', 'roles'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 1 – Roles'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'big-data-5vs',\n",
              "  'term': 'Big Data (5 Vs)',\n",
              "  'definition': 'Large, fast, diverse data where value depends on managing volume, velocity, variety—and quality (veracity)—to produce outcomes (value).\\n',\n",
              "  'examples': ['Clickstream + IoT + social signals for portfolio insights'],\n",
              "  'see_also': ['hadoop', 'apache-spark', 'data-lake'],\n",
              "  'tags': ['ibm', 'big-data'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 2 – Big Data'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'business-analysis',\n",
              "  'term': 'Business Analysis',\n",
              "  'definition': 'A disciplined practice that enables change by defining needs and recommending solutions that deliver value to stakeholders. Emphasizes articulating the rationale for change, shaping solutions, and ensuring delivered outcomes match expected value.\\n',\n",
              "  'examples': ['Scoping FourTwenty initiatives before building (e.g., The Trainer)'],\n",
              "  'see_also': ['babok-guide',\n",
              "   'stakeholder',\n",
              "   'requirements-levels',\n",
              "   'solution-evaluation'],\n",
              "  'tags': ['cbap', 'credentials'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'business-glossary',\n",
              "  'term': 'Business Glossary',\n",
              "  'definition': 'A curated list of noun terms and clear definitions for a domain; the first step in building a Concept Model and reducing ambiguity.\\n',\n",
              "  'examples': ['glossary.yml terms for GA4 events, modules, and roles'],\n",
              "  'see_also': ['concept-modeling', 'data-dictionary'],\n",
              "  'tags': ['cbap', 'knowledge'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 2'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'business-requirements',\n",
              "  'term': 'Business Requirements',\n",
              "  'definition': 'Statements of goals, objectives, and outcomes that justify a change and define what success looks like for the organization (often tied to KPIs).\\n',\n",
              "  'examples': ['Increase GA4 event adoption by 50% within a month'],\n",
              "  'see_also': ['strategy-analysis', 'stakeholder-requirements'],\n",
              "  'tags': ['cbap', 'requirements'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'cbap-certification',\n",
              "  'term': 'CBAP Certification',\n",
              "  'definition': 'IIBA’s top-tier credential for experienced business analysts. Eligibility includes substantial BA experience (e.g., ~7,500 hours over 10 years) and professional development hours, followed by an exam.\\n',\n",
              "  'examples': ['Mapping Zach’s BA/ETL history to CBAP eligibility requirements'],\n",
              "  'see_also': ['iiba', 'babok-guide'],\n",
              "  'tags': ['cbap', 'credentials'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'change',\n",
              "  'term': 'Change',\n",
              "  'definition': 'The act of transformation in response to a Need; deliberate and controlled through BA activities to improve organizational performance.\\n',\n",
              "  'examples': ['Introduce GA4 custom events to improve engagement measurement'],\n",
              "  'see_also': ['need', 'solution', 'context', 'baccm'],\n",
              "  'tags': ['cbap', 'baccm'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 2'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'concept-modeling',\n",
              "  'term': 'Concept Modeling',\n",
              "  'definition': 'A technique to organize a domain’s vocabulary and relationships: start a noun-based glossary, add verb relationships, classify/specialize, and visualize for stakeholder alignment. Business-friendly, but not a data model and may set unrealistic build expectations; benefits from collaborative tools.\\n',\n",
              "  'examples': ['Map FourTwenty terms: Event → is triggered by → Interaction; Event → belongs to → Module'],\n",
              "  'see_also': ['business-glossary',\n",
              "   'data-modeling',\n",
              "   'requirements-levels',\n",
              "   'baccm'],\n",
              "  'tags': ['cbap', 'technique'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP',\n",
              "   'module': 'Module 2 – Technique: Concept Modeling'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'context',\n",
              "  'term': 'Context',\n",
              "  'definition': 'The internal and external circumstances that influence or are influenced by the Change; aligns with ISO 9000’s notion of issues affecting how an organization pursues its objectives.\\n',\n",
              "  'examples': ['Regulatory constraints on PII shape event design'],\n",
              "  'see_also': ['change', 'need', 'solution', 'baccm'],\n",
              "  'tags': ['cbap', 'baccm'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 2'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-analysis-process',\n",
              "  'term': 'Data Analysis Process',\n",
              "  'definition': 'Define the problem and desired outcome, set evaluation metrics, gather and clean data, analyze/mine and interpret, then communicate findings to drive decisions.\\n',\n",
              "  'examples': ['Overbilling case study: hypotheses → datasets → patterns → stakeholder readout'],\n",
              "  'see_also': ['data-wrangling', 'kpi', 'storytelling'],\n",
              "  'tags': ['ibm', 'process'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 1 – Process'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-analyst',\n",
              "  'term': 'Data Analyst',\n",
              "  'definition': 'Translates data into insights by acquiring, cleaning, analyzing, and visualizing data, then communicating findings that inform decisions.\\n',\n",
              "  'examples': ['Analyze engagement WIP/throughput; publish weekly KPI report'],\n",
              "  'see_also': ['descriptive-analytics',\n",
              "   'diagnostic-analytics',\n",
              "   'data-visualization'],\n",
              "  'tags': ['ibm', 'roles'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 1 – Roles'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-ecosystem',\n",
              "  'term': 'Data Ecosystem',\n",
              "  'definition': 'Interconnected people, processes, tools, and infrastructure that acquire, store, process, and disseminate data from diverse sources so stakeholders can generate and act on insights.\\n',\n",
              "  'examples': ['Repo → event stream → warehouse/lake → dashboards for stakeholders'],\n",
              "  'see_also': ['etl', 'governance', 'data-wrangling'],\n",
              "  'tags': ['ibm', 'foundations'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 1 – Intro & Ecosystem'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-engineer',\n",
              "  'term': 'Data Engineer',\n",
              "  'definition': 'Builds and maintains data architectures; integrates data from disparate sources; designs and operates repositories to make data accessible and reliable for analytics and applications.\\n',\n",
              "  'examples': ['Pipeline to collect GA events and land them in a queryable store'],\n",
              "  'see_also': ['etl', 'data-warehouse', 'data-lake'],\n",
              "  'tags': ['ibm', 'roles'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 1 – Roles'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-lake',\n",
              "  'term': 'Data Lake',\n",
              "  'definition': 'Storage for raw structured, semi-structured, and unstructured data in native formats, tagged for later processing.\\n',\n",
              "  'examples': ['Raw GA4 export + scraped FAQs for feature discovery'],\n",
              "  'see_also': ['data-warehouse', 'etl', 'nosql-database'],\n",
              "  'tags': ['ibm', 'repositories'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Repositories'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-mart',\n",
              "  'term': 'Data Mart',\n",
              "  'definition': 'Subject-area slice of a warehouse with isolated performance/security for a team or function.\\n',\n",
              "  'examples': ['Marketing mart with engagement and campaign tables'],\n",
              "  'see_also': ['data-warehouse', 'data-lake'],\n",
              "  'tags': ['ibm', 'repositories'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Repositories'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-pipeline',\n",
              "  'term': 'Data Pipeline',\n",
              "  'definition': 'End-to-end system that moves/processes data (batch, streaming, or hybrid) from sources to destinations (lakes, apps, viz), of which ETL is a subset.\\n',\n",
              "  'examples': ['Event stream → stream processor → lake → dashboard'],\n",
              "  'see_also': ['etl', 'data-lake', 'apache-spark'],\n",
              "  'tags': ['ibm', 'pipelines'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – ETL & Pipelines'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-scientist',\n",
              "  'term': 'Data Scientist',\n",
              "  'definition': 'Uses statistical and machine learning techniques to build predictive or prescriptive models, often requiring programming and domain knowledge.\\n',\n",
              "  'examples': ['Forecast conversion rate from historical session data'],\n",
              "  'see_also': ['predictive-analytics',\n",
              "   'prescriptive-analytics',\n",
              "   'feature-engineering'],\n",
              "  'tags': ['ibm', 'roles'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 1 – Roles'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-sources',\n",
              "  'term': 'Data Sources',\n",
              "  'definition': 'Origins of data for analytics: relational/non-relational databases, flat files/spreadsheets, APIs/web services, web scraping, data streams, social and sensor feeds.\\n',\n",
              "  'examples': ['Twitter API for sentiment; Kafka clickstream; CRM DB extract'],\n",
              "  'see_also': ['relational-database',\n",
              "   'nosql-database',\n",
              "   'data-streams',\n",
              "   'web-scraping'],\n",
              "  'tags': ['ibm', 'sources'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 2 – Sources'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-streams',\n",
              "  'term': 'Data Streams',\n",
              "  'definition': 'Continuous, time-stamped event feeds from devices, apps, and services used for real-time analysis.\\n',\n",
              "  'examples': ['Pageview and engagement events flowing to a stream processor'],\n",
              "  'see_also': ['etl', 'data-pipeline', 'apache-spark'],\n",
              "  'tags': ['ibm', 'sources', 'streaming'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 2 – Sources'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-warehouse',\n",
              "  'term': 'Data Warehouse',\n",
              "  'definition': 'Central, analysis-ready repository integrating cleansed and conformed data for BI/analytics.\\n',\n",
              "  'examples': ['Conformed sessions, events, and outcomes for portfolio-wide KPIs'],\n",
              "  'see_also': ['data-mart', 'etl', 'data-pipeline'],\n",
              "  'tags': ['ibm', 'repositories'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Repositories'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'delimited-text-file',\n",
              "  'term': 'Delimited Text File (CSV/TSV)',\n",
              "  'definition': 'Plain-text rows where fields are separated by a delimiter (comma, tab, etc.); widely supported, schema described by header row.\\n',\n",
              "  'examples': ['Exported KPI table as CSV for The Trainer'],\n",
              "  'see_also': ['xlsx', 'json', 'data-warehouse'],\n",
              "  'tags': ['ibm', 'formats'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – File Formats'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'descriptive-analytics',\n",
              "  'term': 'Descriptive Analytics',\n",
              "  'definition': 'Summarizes past data to show what happened over a period; baseline for monitoring KPIs and trends.\\n',\n",
              "  'examples': ['Weekly pageviews by source in The Trainer'],\n",
              "  'see_also': ['diagnostic-analytics', 'kpi'],\n",
              "  'tags': ['ibm', 'analytics-types'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 1 – Analysis Types'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'diagnostic-analytics',\n",
              "  'term': 'Diagnostic Analytics',\n",
              "  'definition': 'Investigates why an outcome occurred by drilling into segments, correlations, and drivers.\\n',\n",
              "  'examples': ['Explain a traffic spike by campaign, landing page, and device'],\n",
              "  'see_also': ['descriptive-analytics', 'root-cause'],\n",
              "  'tags': ['ibm', 'analytics-types'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 1 – Analysis Types'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'elicitation',\n",
              "  'term': 'Elicitation & Collaboration',\n",
              "  'definition': 'Activities to uncover needs and requirements and to align stakeholder understanding through interviews, workshops, observation, and co-design.\\n',\n",
              "  'examples': ['Stakeholder discovery for GA4+GTM sprint goals'],\n",
              "  'see_also': ['stakeholder', 'requirements-levels'],\n",
              "  'tags': ['cbap', 'requirements'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'etl',\n",
              "  'term': 'Extract, Transform, Load (ETL)',\n",
              "  'definition': 'Automated process to acquire data from sources, clean/standardize/enrich, and load into a target repository; supports batch and streaming variants.\\n',\n",
              "  'examples': ['Nightly CSV ingest + real-time event transforms for ‘The Trainer’'],\n",
              "  'see_also': ['data-pipeline', 'data-warehouse'],\n",
              "  'tags': ['ibm', 'pipelines'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – ETL & Pipelines'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'functional-requirements',\n",
              "  'term': 'Functional Requirements',\n",
              "  'definition': 'Behaviors the solution performs in response to inputs or events, often captured as acceptance criteria for user stories.\\n',\n",
              "  'examples': [\"Trigger 'scroll_opened' GA event when README panel expands\"],\n",
              "  'see_also': ['solution-requirements', 'non-functional-requirements'],\n",
              "  'tags': ['cbap', 'requirements'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'generative-ai-for-analysts',\n",
              "  'term': 'Generative AI for Analysts',\n",
              "  'definition': 'Models that create new content (text, images, code) and can accelerate analysis via summarization, data augmentation, scenario simulation, and automated drafting—used responsibly with awareness of limitations and bias.\\n',\n",
              "  'examples': ['Draft a findings summary; synthesize scenarios; generate synthetic edge cases'],\n",
              "  'see_also': ['predictive-analytics', 'ethics', 'quality-assurance'],\n",
              "  'tags': ['ibm', 'genai'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 1 – Generative AI overview'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'given-when-then',\n",
              "  'term': 'Given–When–Then (GWT)',\n",
              "  'definition': 'A behavior-driven format for functional acceptance criteria capturing preconditions, action, and expected outcome (e.g., ‘Given on checkout, When user selects BNPL, Then open third-party interface’).\\n',\n",
              "  'examples': ['Define acceptance tests for custom event capture'],\n",
              "  'see_also': ['functional-requirements', 'solution-requirements'],\n",
              "  'tags': ['cbap', 'requirements', 'bdd'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 2 – Requirements Details'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'hadoop',\n",
              "  'term': 'Apache Hadoop',\n",
              "  'definition': 'Open-source ecosystem for distributed storage/processing of large datasets across clusters; often paired with HDFS and Hive.\\n',\n",
              "  'examples': ['Archive cold data to HDFS-backed storage'],\n",
              "  'see_also': ['hdfs', 'hive', 'apache-spark'],\n",
              "  'tags': ['ibm', 'big-data'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Big Data Tools'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'hdfs',\n",
              "  'term': 'Hadoop Distributed File System (HDFS)',\n",
              "  'definition': 'Fault-tolerant, distributed storage that partitions/replicates files across nodes and lets computation run where data resides.\\n',\n",
              "  'examples': ['Store large raw parquet files with 3x replication'],\n",
              "  'see_also': ['hadoop', 'apache-spark'],\n",
              "  'tags': ['ibm', 'big-data'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Big Data Tools'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'hive',\n",
              "  'term': 'Apache Hive',\n",
              "  'definition': 'SQL-on-Hadoop data warehouse layer optimized for batch/long scans; unsuitable for low-latency transactions.\\n',\n",
              "  'examples': ['Ad-hoc aggregates on raw clickstream in HDFS'],\n",
              "  'see_also': ['hadoop', 'apache-spark'],\n",
              "  'tags': ['ibm', 'big-data', 'sql'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Big Data Tools'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'iiba',\n",
              "  'term': 'International Institute of Business Analysis (IIBA)',\n",
              "  'definition': 'A global non-profit association for business analysis that maintains standards (including the BABOK Guide) and offers certifications such as ECBA, CCBA, and CBAP.\\n',\n",
              "  'examples': ['Using ECBA/CCBA/CBAP levels to frame credentials on the Portfolio'],\n",
              "  'see_also': ['babok-guide', 'cbap-certification'],\n",
              "  'tags': ['cbap', 'credentials'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'json',\n",
              "  'term': 'JSON',\n",
              "  'definition': 'Lightweight text format for structured data (key/value, arrays); common for APIs/web services.\\n',\n",
              "  'examples': ['GTM → GA4 event payloads'],\n",
              "  'see_also': ['xml', 'semi-structured-data', 'nosql-database'],\n",
              "  'tags': ['ibm', 'formats'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – File Formats'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'need',\n",
              "  'term': 'Need',\n",
              "  'definition': 'A problem or opportunity that motivates Change; needs can trigger changes and new changes can introduce further needs (iterative cycle).\\n',\n",
              "  'examples': ['Low funnel visibility → add checkout events; later, need for attribution refinement'],\n",
              "  'see_also': ['change', 'solution', 'value', 'baccm'],\n",
              "  'tags': ['cbap', 'baccm'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 2'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'non-functional-requirements',\n",
              "  'term': 'Non-Functional Requirements (Quality Attributes)',\n",
              "  'definition': 'Conditions under which the solution must remain effective (e.g., security, performance, availability, accessibility, maintainability, recoverability, audit).\\n',\n",
              "  'examples': ['Handle 100 requests per minute without delayed response'],\n",
              "  'see_also': ['solution-requirements', 'solution-evaluation'],\n",
              "  'tags': ['cbap', 'quality'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'nosql-database',\n",
              "  'term': 'NoSQL Database',\n",
              "  'definition': 'Non-relational stores with flexible schemas; common models include key-value, document, column-family, and graph—optimized for scale/performance.\\n',\n",
              "  'examples': ['Document store for event payloads; key-value cache for sessions'],\n",
              "  'see_also': ['relational-database', 'data-lake'],\n",
              "  'tags': ['ibm', 'repositories'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Databases & Repositories'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'perspective',\n",
              "  'term': 'Perspective (BA Flavor)',\n",
              "  'definition': 'An organizational context or delivery approach (e.g., agile, process-centric, product-led) that shapes which techniques you use and how you apply BA tasks.\\n',\n",
              "  'examples': ['Adapting Trainer backlog practices for a startup vs. a risk-averse enterprise'],\n",
              "  'see_also': ['babok-knowledge-areas', 'underlying-competencies'],\n",
              "  'tags': ['cbap', 'approach'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'predictive-analytics',\n",
              "  'term': 'Predictive Analytics',\n",
              "  'definition': 'Uses historical patterns to estimate the likelihood of future outcomes; results are probabilistic.\\n',\n",
              "  'examples': ['Forecast weekly sessions from seasonal history'],\n",
              "  'see_also': ['time-series', 'data-scientist'],\n",
              "  'tags': ['ibm', 'analytics-types'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 1 – Analysis Types'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'prescriptive-analytics',\n",
              "  'term': 'Prescriptive Analytics',\n",
              "  'definition': 'Evaluates possible actions and their likely outcomes to recommend what to do next.\\n',\n",
              "  'examples': ['Choose promo variant that maximizes predicted conversions'],\n",
              "  'see_also': ['predictive-analytics', 'optimization'],\n",
              "  'tags': ['ibm', 'analytics-types'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 1 – Analysis Types'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'python',\n",
              "  'term': 'Python',\n",
              "  'definition': 'General-purpose language with rich analytics libraries (NumPy, pandas); readable syntax and strong community—common for data prep, ML, and ETL.\\n',\n",
              "  'examples': ['pandas transform for GA4 event features'],\n",
              "  'see_also': ['apache-spark', 'sql', 'r-language'],\n",
              "  'tags': ['ibm', 'languages'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 2 – Languages'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'r-language',\n",
              "  'term': 'R (Language)',\n",
              "  'definition': 'Open-source environment for statistics, visualization, and analysis; extensible ecosystem (ggplot2, plotly) and report/app publishing.\\n',\n",
              "  'examples': ['Exploratory plots for streak patterns'],\n",
              "  'see_also': ['python', 'sql'],\n",
              "  'tags': ['ibm', 'languages'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 2 – Languages'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'relational-database',\n",
              "  'term': 'Relational Database (RDBMS)',\n",
              "  'definition': 'Table-based store with defined schema and SQL querying; supports joins, integrity constraints, and ACID properties.\\n',\n",
              "  'examples': ['Dimensional model for reporting KPIs'],\n",
              "  'see_also': ['sql', 'nosql-database', 'data-warehouse'],\n",
              "  'tags': ['ibm', 'repositories'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Databases & Repositories'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'requirements-levels',\n",
              "  'term': 'Requirements Levels',\n",
              "  'definition': 'BABOK groups requirements into four levels: Business (why outcomes), Stakeholder (needs/expectations by actor), Solution (capabilities and qualities), and Transition (temporary needs to move from current to future state).\\n',\n",
              "  'examples': ['Mapping Trainer goals → user stories → acceptance criteria → rollout plan'],\n",
              "  'see_also': ['business-requirements',\n",
              "   'stakeholder-requirements',\n",
              "   'solution-requirements',\n",
              "   'transition-requirements'],\n",
              "  'tags': ['cbap', 'requirements'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'requirements-lifecycle-management',\n",
              "  'term': 'Requirements Life Cycle Management',\n",
              "  'definition': 'Planning, tracing, maintaining, prioritizing, and approving requirements from discovery through change, ensuring they remain current and aligned to value.\\n',\n",
              "  'examples': ['Trace GA4 events to stakeholder outcomes and update as scope changes'],\n",
              "  'see_also': ['requirements-levels', 'solution-requirements'],\n",
              "  'tags': ['cbap', 'requirements'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'semi-structured-data',\n",
              "  'term': 'Semi-Structured Data',\n",
              "  'definition': 'Data with organizational properties but no rigid schema; uses tags/metadata (e.g., XML/JSON) and is often hierarchical.\\n',\n",
              "  'examples': ['Webhook JSON payloads for events'],\n",
              "  'see_also': ['structured-data',\n",
              "   'unstructured-data',\n",
              "   'json',\n",
              "   'xml',\n",
              "   'nosql-database'],\n",
              "  'tags': ['ibm', 'data-types'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Data Types & Sources'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'solution',\n",
              "  'term': 'Solution',\n",
              "  'definition': 'A specific way to satisfy one or more Needs by resolving a problem or enabling an opportunity.\\n',\n",
              "  'examples': ['Deploy GTM container with standardized event schema'],\n",
              "  'see_also': ['need', 'value', 'stakeholder', 'baccm'],\n",
              "  'tags': ['cbap', 'baccm'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 2'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'solution-evaluation',\n",
              "  'term': 'Solution Evaluation',\n",
              "  'definition': 'Assessing a solution’s performance and value after or during delivery to verify it achieves the desired outcomes and to identify improvements.\\n',\n",
              "  'examples': ['Validate GA4 custom events deliver the engagement metrics promised'],\n",
              "  'see_also': ['business-requirements', 'non-functional-requirements'],\n",
              "  'tags': ['cbap', 'quality'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'solution-requirements',\n",
              "  'term': 'Solution Requirements',\n",
              "  'definition': 'Capabilities and qualities the solution must have to meet stakeholder needs; split into functional (behaviors/acceptance criteria) and non-functional (quality attributes and constraints).\\n',\n",
              "  'examples': ['Send reminder email when session expires and items remain in cart'],\n",
              "  'see_also': ['functional-requirements', 'non-functional-requirements'],\n",
              "  'tags': ['cbap', 'requirements'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'sql',\n",
              "  'term': 'SQL',\n",
              "  'definition': 'Standard query language for creating and manipulating relational data (tables, views, joins, DML/DDL, stored procedures).\\n',\n",
              "  'examples': ['Windowed KPI rollups in a warehouse'],\n",
              "  'see_also': ['relational-database', 'hive'],\n",
              "  'tags': ['ibm', 'languages'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 2 – Languages'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'stakeholder',\n",
              "  'term': 'Stakeholder',\n",
              "  'definition': 'Any person, group, or organization with a role in, interest in, or impact from a change. Stakeholders supply needs, consume outcomes, and collaborate to define value.\\n',\n",
              "  'examples': ['Data consumer for GA4 metrics (marketing analyst, product owner)'],\n",
              "  'see_also': ['elicitation', 'stakeholder-requirements'],\n",
              "  'tags': ['cbap'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'stakeholder-requirements',\n",
              "  'term': 'Stakeholder Requirements',\n",
              "  'definition': 'Needs and expectations of specific stakeholders or user groups, often expressed as user stories to clarify who needs what and why.\\n',\n",
              "  'examples': ['As a visitor, I want my cart retained so I can resume later'],\n",
              "  'see_also': ['business-requirements',\n",
              "   'solution-requirements',\n",
              "   'elicitation'],\n",
              "  'tags': ['cbap', 'requirements'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'strategy-analysis',\n",
              "  'term': 'Strategy Analysis',\n",
              "  'definition': 'Pre-project analysis to understand the current and future states, define business goals and scope, and select initiatives that deliver value.\\n',\n",
              "  'examples': ['Define objectives for The Trainer (ritual cadence, streak goals)'],\n",
              "  'see_also': ['business-requirements', 'solution-evaluation'],\n",
              "  'tags': ['cbap', 'planning'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'structured-data',\n",
              "  'term': 'Structured Data',\n",
              "  'definition': 'Data with a well-defined schema (rows/columns) that fits relational tables and standard analytical methods.\\n',\n",
              "  'examples': ['Survey response table; GA session table'],\n",
              "  'see_also': ['semi-structured-data',\n",
              "   'unstructured-data',\n",
              "   'relational-database'],\n",
              "  'tags': ['ibm', 'data-types'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Data Types & Sources'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'transition-requirements',\n",
              "  'term': 'Transition Requirements',\n",
              "  'definition': 'Temporary capabilities and conditions needed to move from current to future state, such as data migration, training, and phased releases.\\n',\n",
              "  'examples': ['Migrate historic events to new GA4 property; train contributors'],\n",
              "  'see_also': ['requirements-levels', 'solution-evaluation'],\n",
              "  'tags': ['cbap', 'delivery'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'underlying-competencies',\n",
              "  'term': 'Underlying Competencies',\n",
              "  'definition': 'Human skills and business knowledge that complement BA methods—communication, facilitation, critical thinking, domain awareness—enabling effective practice.\\n',\n",
              "  'examples': ['Facilitating a cross-module retro for The Trainer'],\n",
              "  'see_also': ['elicitation', 'perspective'],\n",
              "  'tags': ['cbap', 'skills'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'unstructured-data',\n",
              "  'term': 'Unstructured Data',\n",
              "  'definition': 'Data without a predefined format (text, images, audio/video, PDFs) that does not map cleanly to rows/columns.\\n',\n",
              "  'examples': ['Session recordings, support emails, screenshots'],\n",
              "  'see_also': ['semi-structured-data', 'data-lake', 'nosql-database'],\n",
              "  'tags': ['ibm', 'data-types'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Data Types & Sources'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'value',\n",
              "  'term': 'Value',\n",
              "  'definition': 'The importance or usefulness of something to a Stakeholder; can be delivered by different Solutions and may be tangible (e.g., revenue, cost) or intangible (e.g., ease of use, brand loyalty).\\n',\n",
              "  'examples': ['Faster dashboard load → higher satisfaction (intangible); reduced churn (tangible)'],\n",
              "  'see_also': ['stakeholder', 'solution', 'need', 'baccm'],\n",
              "  'tags': ['cbap', 'baccm'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 2'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'xlsx',\n",
              "  'term': 'XLSX (Excel Workbook)',\n",
              "  'definition': 'Open XML spreadsheet format with multiple worksheets; tabular cells with formulas/formatting.\\n',\n",
              "  'examples': ['Manual backlog tracker with streak metrics'],\n",
              "  'see_also': ['delimited-text-file', 'data-wrangling'],\n",
              "  'tags': ['ibm', 'formats'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – File Formats'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'xml',\n",
              "  'term': 'XML',\n",
              "  'definition': 'Tag-based markup for structured exchange; human/machine readable; platform/language independent.\\n',\n",
              "  'examples': ['Survey exports with hierarchical question blocks'],\n",
              "  'see_also': ['json', 'semi-structured-data'],\n",
              "  'tags': ['ibm', 'formats'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – File Formats'},\n",
              "  'status': 'draft'}]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = f\"{BASE}/modules/trainer-model/data/merge_map.csv\"\n",
        "merge_from_csv(csv_path, out=out_path, dry_run=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKFTwJDSNIfi",
        "outputId": "e77dec59-61fc-4bd7-a76b-269a63b86448"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[summary] files=5 items_in=88 unique=64 deduped=24\n",
            "[ok] wrote /content/drive/MyDrive/FourTwentyAnalytics/modules/trainer-model/seeds/glossary.yml\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'key': 'analyst-skills',\n",
              "  'term': 'Analyst Skills (Technical, Functional, Soft)',\n",
              "  'definition': 'Blend of tool proficiency (spreadsheets, SQL, viz tools, programming), functional capabilities (statistics, analytical thinking, problem-solving, probing, project management), and soft skills (collaboration, communication, storytelling, curiosity, informed intuition).\\n',\n",
              "  'examples': ['SQL for joins; Power BI dashboards; stakeholder workshop; narrative readout'],\n",
              "  'see_also': ['sql', 'data-visualization', 'statistics', 'storytelling'],\n",
              "  'tags': ['ibm', 'skills'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 1 – Skills'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'apache-spark',\n",
              "  'term': 'Apache Spark',\n",
              "  'definition': 'Distributed processing engine (batch & streaming) with in-memory acceleration and APIs for SQL, Python, R, Java/Scala.\\n',\n",
              "  'examples': ['Process engagement stream to compute rolling WIP/throughput'],\n",
              "  'see_also': ['hadoop', 'hdfs', 'data-streams'],\n",
              "  'tags': ['ibm', 'big-data', 'streaming'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Big Data Tools'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'babok-guide',\n",
              "  'term': 'BABOK Guide',\n",
              "  'definition': 'The Guide to the Business Analysis Body of Knowledge from IIBA that defines the profession and describes commonly accepted practices, knowledge areas, tasks, techniques, and underlying competencies.\\n',\n",
              "  'examples': ['Referencing BABOK when mapping The Trainer tasks to knowledge areas'],\n",
              "  'see_also': ['iiba', 'babok-knowledge-areas'],\n",
              "  'tags': ['cbap', 'standard'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'babok-knowledge-areas',\n",
              "  'term': 'BABOK Knowledge Areas',\n",
              "  'definition': 'Six domains that organize BA work: Business Analysis Planning & Monitoring; Elicitation & Collaboration; Requirements Life Cycle Management; Strategy Analysis; Requirements Analysis & Design Definition; and Solution Evaluation.\\n',\n",
              "  'examples': ['Tagging Trainer tasks with the relevant knowledge area'],\n",
              "  'see_also': ['elicitation',\n",
              "   'requirements-lifecycle-management',\n",
              "   'strategy-analysis',\n",
              "   'solution-evaluation'],\n",
              "  'tags': ['cbap', 'framework'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'baccm',\n",
              "  'term': 'Business Analysis Core Concept Model (BACCM)',\n",
              "  'definition': 'A shared mental framework for business analysis built on six equal concepts— Change, Need, Solution, Stakeholder, Value, and Context—used to frame any BA task regardless of domain or methodology.\\n',\n",
              "  'examples': ['Framing The Trainer: identify the Need, define the Change and Solution, map Stakeholders, value, and Context'],\n",
              "  'see_also': ['change',\n",
              "   'need',\n",
              "   'solution',\n",
              "   'stakeholder',\n",
              "   'value',\n",
              "   'context',\n",
              "   'babok-guide'],\n",
              "  'tags': ['cbap', 'framework'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 2 – BACCM & Techniques'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'bi-analyst',\n",
              "  'term': 'Business Intelligence (BI) Analyst',\n",
              "  'definition': 'Organizes and monitors business data, builds standardized reports/dashboards, and explores trends to support performance decisions, often with market/external focus.\\n',\n",
              "  'examples': ['Power BI sales dashboard with daily refresh and drill-downs'],\n",
              "  'see_also': ['data-analyst', 'kpi', 'dashboard'],\n",
              "  'tags': ['ibm', 'roles'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 1 – Roles'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'big-data-5vs',\n",
              "  'term': 'Big Data (5 Vs)',\n",
              "  'definition': 'Large, fast, diverse data where value depends on managing volume, velocity, variety—and quality (veracity)—to produce outcomes (value).\\n',\n",
              "  'examples': ['Clickstream + IoT + social signals for portfolio insights'],\n",
              "  'see_also': ['hadoop', 'apache-spark', 'data-lake'],\n",
              "  'tags': ['ibm', 'big-data'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 2 – Big Data'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'business-analysis',\n",
              "  'term': 'Business Analysis',\n",
              "  'definition': 'A disciplined practice that enables change by defining needs and recommending solutions that deliver value to stakeholders. Emphasizes articulating the rationale for change, shaping solutions, and ensuring delivered outcomes match expected value.\\n',\n",
              "  'examples': ['Scoping FourTwenty initiatives before building (e.g., The Trainer)'],\n",
              "  'see_also': ['babok-guide',\n",
              "   'stakeholder',\n",
              "   'requirements-levels',\n",
              "   'solution-evaluation'],\n",
              "  'tags': ['cbap', 'credentials'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'business-glossary',\n",
              "  'term': 'Business Glossary',\n",
              "  'definition': 'A curated list of noun terms and clear definitions for a domain; the first step in building a Concept Model and reducing ambiguity.\\n',\n",
              "  'examples': ['glossary.yml terms for GA4 events, modules, and roles'],\n",
              "  'see_also': ['concept-modeling', 'data-dictionary'],\n",
              "  'tags': ['cbap', 'knowledge'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 2'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'business-requirements',\n",
              "  'term': 'Business Requirements',\n",
              "  'definition': 'Statements of goals, objectives, and outcomes that justify a change and define what success looks like for the organization (often tied to KPIs).\\n',\n",
              "  'examples': ['Increase GA4 event adoption by 50% within a month'],\n",
              "  'see_also': ['strategy-analysis', 'stakeholder-requirements'],\n",
              "  'tags': ['cbap', 'requirements'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'cbap-certification',\n",
              "  'term': 'CBAP Certification',\n",
              "  'definition': 'IIBA’s top-tier credential for experienced business analysts. Eligibility includes substantial BA experience (e.g., ~7,500 hours over 10 years) and professional development hours, followed by an exam.\\n',\n",
              "  'examples': ['Mapping Zach’s BA/ETL history to CBAP eligibility requirements'],\n",
              "  'see_also': ['iiba', 'babok-guide'],\n",
              "  'tags': ['cbap', 'credentials'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'change',\n",
              "  'term': 'Change',\n",
              "  'definition': 'The act of transformation in response to a Need; deliberate and controlled through BA activities to improve organizational performance.\\n',\n",
              "  'examples': ['Introduce GA4 custom events to improve engagement measurement'],\n",
              "  'see_also': ['need', 'solution', 'context', 'baccm'],\n",
              "  'tags': ['cbap', 'baccm'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 2'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'concept-modeling',\n",
              "  'term': 'Concept Modeling',\n",
              "  'definition': 'A technique to organize a domain’s vocabulary and relationships: start a noun-based glossary, add verb relationships, classify/specialize, and visualize for stakeholder alignment. Business-friendly, but not a data model and may set unrealistic build expectations; benefits from collaborative tools.\\n',\n",
              "  'examples': ['Map FourTwenty terms: Event → is triggered by → Interaction; Event → belongs to → Module'],\n",
              "  'see_also': ['business-glossary',\n",
              "   'data-modeling',\n",
              "   'requirements-levels',\n",
              "   'baccm'],\n",
              "  'tags': ['cbap', 'technique'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP',\n",
              "   'module': 'Module 2 – Technique: Concept Modeling'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'context',\n",
              "  'term': 'Context',\n",
              "  'definition': 'The internal and external circumstances that influence or are influenced by the Change; aligns with ISO 9000’s notion of issues affecting how an organization pursues its objectives.\\n',\n",
              "  'examples': ['Regulatory constraints on PII shape event design'],\n",
              "  'see_also': ['change', 'need', 'solution', 'baccm'],\n",
              "  'tags': ['cbap', 'baccm'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 2'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-analysis-process',\n",
              "  'term': 'Data Analysis Process',\n",
              "  'definition': 'Define the problem and desired outcome, set evaluation metrics, gather and clean data, analyze/mine and interpret, then communicate findings to drive decisions.\\n',\n",
              "  'examples': ['Overbilling case study: hypotheses → datasets → patterns → stakeholder readout'],\n",
              "  'see_also': ['data-wrangling', 'kpi', 'storytelling'],\n",
              "  'tags': ['ibm', 'process'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 1 – Process'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-analyst',\n",
              "  'term': 'Data Analyst',\n",
              "  'definition': 'Translates data into insights by acquiring, cleaning, analyzing, and visualizing data, then communicating findings that inform decisions.\\n',\n",
              "  'examples': ['Analyze engagement WIP/throughput; publish weekly KPI report'],\n",
              "  'see_also': ['descriptive-analytics',\n",
              "   'diagnostic-analytics',\n",
              "   'data-visualization'],\n",
              "  'tags': ['ibm', 'roles'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 1 – Roles'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-ecosystem',\n",
              "  'term': 'Data Ecosystem',\n",
              "  'definition': 'Interconnected people, processes, tools, and infrastructure that acquire, store, process, and disseminate data from diverse sources so stakeholders can generate and act on insights.\\n',\n",
              "  'examples': ['Repo → event stream → warehouse/lake → dashboards for stakeholders'],\n",
              "  'see_also': ['etl', 'governance', 'data-wrangling'],\n",
              "  'tags': ['ibm', 'foundations'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 1 – Intro & Ecosystem'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-engineer',\n",
              "  'term': 'Data Engineer',\n",
              "  'definition': 'Builds and maintains data architectures; integrates data from disparate sources; designs and operates repositories to make data accessible and reliable for analytics and applications.\\n',\n",
              "  'examples': ['Pipeline to collect GA events and land them in a queryable store'],\n",
              "  'see_also': ['etl', 'data-warehouse', 'data-lake'],\n",
              "  'tags': ['ibm', 'roles'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 1 – Roles'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-lake',\n",
              "  'term': 'Data Lake',\n",
              "  'definition': 'Storage for raw structured, semi-structured, and unstructured data in native formats, tagged for later processing.\\n',\n",
              "  'examples': ['Raw GA4 export + scraped FAQs for feature discovery'],\n",
              "  'see_also': ['data-warehouse', 'etl', 'nosql-database'],\n",
              "  'tags': ['ibm', 'repositories'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Repositories'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-mart',\n",
              "  'term': 'Data Mart',\n",
              "  'definition': 'Subject-area slice of a warehouse with isolated performance/security for a team or function.\\n',\n",
              "  'examples': ['Marketing mart with engagement and campaign tables'],\n",
              "  'see_also': ['data-warehouse', 'data-lake'],\n",
              "  'tags': ['ibm', 'repositories'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Repositories'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-pipeline',\n",
              "  'term': 'Data Pipeline',\n",
              "  'definition': 'End-to-end system that moves/processes data (batch, streaming, or hybrid) from sources to destinations (lakes, apps, viz), of which ETL is a subset.\\n',\n",
              "  'examples': ['Event stream → stream processor → lake → dashboard'],\n",
              "  'see_also': ['etl', 'data-lake', 'apache-spark'],\n",
              "  'tags': ['ibm', 'pipelines'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – ETL & Pipelines'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-scientist',\n",
              "  'term': 'Data Scientist',\n",
              "  'definition': 'Uses statistical and machine learning techniques to build predictive or prescriptive models, often requiring programming and domain knowledge.\\n',\n",
              "  'examples': ['Forecast conversion rate from historical session data'],\n",
              "  'see_also': ['predictive-analytics',\n",
              "   'prescriptive-analytics',\n",
              "   'feature-engineering'],\n",
              "  'tags': ['ibm', 'roles'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 1 – Roles'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-sources',\n",
              "  'term': 'Data Sources',\n",
              "  'definition': 'Origins of data for analytics: relational/non-relational databases, flat files/spreadsheets, APIs/web services, web scraping, data streams, social and sensor feeds.\\n',\n",
              "  'examples': ['Twitter API for sentiment; Kafka clickstream; CRM DB extract'],\n",
              "  'see_also': ['relational-database',\n",
              "   'nosql-database',\n",
              "   'data-streams',\n",
              "   'web-scraping'],\n",
              "  'tags': ['ibm', 'sources'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 2 – Sources'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-streams',\n",
              "  'term': 'Data Streams',\n",
              "  'definition': 'Continuous, time-stamped event feeds from devices, apps, and services used for real-time analysis.\\n',\n",
              "  'examples': ['Pageview and engagement events flowing to a stream processor'],\n",
              "  'see_also': ['etl', 'data-pipeline', 'apache-spark'],\n",
              "  'tags': ['ibm', 'sources', 'streaming'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 2 – Sources'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'data-warehouse',\n",
              "  'term': 'Data Warehouse',\n",
              "  'definition': 'Central, analysis-ready repository integrating cleansed and conformed data for BI/analytics.\\n',\n",
              "  'examples': ['Conformed sessions, events, and outcomes for portfolio-wide KPIs'],\n",
              "  'see_also': ['data-mart', 'etl', 'data-pipeline'],\n",
              "  'tags': ['ibm', 'repositories'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Repositories'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'delimited-text-file',\n",
              "  'term': 'Delimited Text File (CSV/TSV)',\n",
              "  'definition': 'Plain-text rows where fields are separated by a delimiter (comma, tab, etc.); widely supported, schema described by header row.\\n',\n",
              "  'examples': ['Exported KPI table as CSV for The Trainer'],\n",
              "  'see_also': ['xlsx', 'json', 'data-warehouse'],\n",
              "  'tags': ['ibm', 'formats'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – File Formats'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'descriptive-analytics',\n",
              "  'term': 'Descriptive Analytics',\n",
              "  'definition': 'Summarizes past data to show what happened over a period; baseline for monitoring KPIs and trends.\\n',\n",
              "  'examples': ['Weekly pageviews by source in The Trainer'],\n",
              "  'see_also': ['diagnostic-analytics', 'kpi'],\n",
              "  'tags': ['ibm', 'analytics-types'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 1 – Analysis Types'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'diagnostic-analytics',\n",
              "  'term': 'Diagnostic Analytics',\n",
              "  'definition': 'Investigates why an outcome occurred by drilling into segments, correlations, and drivers.\\n',\n",
              "  'examples': ['Explain a traffic spike by campaign, landing page, and device'],\n",
              "  'see_also': ['descriptive-analytics', 'root-cause'],\n",
              "  'tags': ['ibm', 'analytics-types'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 1 – Analysis Types'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'elicitation',\n",
              "  'term': 'Elicitation & Collaboration',\n",
              "  'definition': 'Activities to uncover needs and requirements and to align stakeholder understanding through interviews, workshops, observation, and co-design.\\n',\n",
              "  'examples': ['Stakeholder discovery for GA4+GTM sprint goals'],\n",
              "  'see_also': ['stakeholder', 'requirements-levels'],\n",
              "  'tags': ['cbap', 'requirements'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'etl',\n",
              "  'term': 'Extract, Transform, Load (ETL)',\n",
              "  'definition': 'Automated process to acquire data from sources, clean/standardize/enrich, and load into a target repository; supports batch and streaming variants.\\n',\n",
              "  'examples': ['Nightly CSV ingest + real-time event transforms for ‘The Trainer’'],\n",
              "  'see_also': ['data-pipeline', 'data-warehouse'],\n",
              "  'tags': ['ibm', 'pipelines'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – ETL & Pipelines'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'functional-requirements',\n",
              "  'term': 'Functional Requirements',\n",
              "  'definition': 'Behaviors the solution performs in response to inputs or events, often captured as acceptance criteria for user stories.\\n',\n",
              "  'examples': [\"Trigger 'scroll_opened' GA event when README panel expands\"],\n",
              "  'see_also': ['solution-requirements', 'non-functional-requirements'],\n",
              "  'tags': ['cbap', 'requirements'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'generative-ai-for-analysts',\n",
              "  'term': 'Generative AI for Analysts',\n",
              "  'definition': 'Models that create new content (text, images, code) and can accelerate analysis via summarization, data augmentation, scenario simulation, and automated drafting—used responsibly with awareness of limitations and bias.\\n',\n",
              "  'examples': ['Draft a findings summary; synthesize scenarios; generate synthetic edge cases'],\n",
              "  'see_also': ['predictive-analytics', 'ethics', 'quality-assurance'],\n",
              "  'tags': ['ibm', 'genai'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 1 – Generative AI overview'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'given-when-then',\n",
              "  'term': 'Given–When–Then (GWT)',\n",
              "  'definition': 'A behavior-driven format for functional acceptance criteria capturing preconditions, action, and expected outcome (e.g., ‘Given on checkout, When user selects BNPL, Then open third-party interface’).\\n',\n",
              "  'examples': ['Define acceptance tests for custom event capture'],\n",
              "  'see_also': ['functional-requirements', 'solution-requirements'],\n",
              "  'tags': ['cbap', 'requirements', 'bdd'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 2 – Requirements Details'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'hadoop',\n",
              "  'term': 'Apache Hadoop',\n",
              "  'definition': 'Open-source ecosystem for distributed storage/processing of large datasets across clusters; often paired with HDFS and Hive.\\n',\n",
              "  'examples': ['Archive cold data to HDFS-backed storage'],\n",
              "  'see_also': ['hdfs', 'hive', 'apache-spark'],\n",
              "  'tags': ['ibm', 'big-data'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Big Data Tools'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'hdfs',\n",
              "  'term': 'Hadoop Distributed File System (HDFS)',\n",
              "  'definition': 'Fault-tolerant, distributed storage that partitions/replicates files across nodes and lets computation run where data resides.\\n',\n",
              "  'examples': ['Store large raw parquet files with 3x replication'],\n",
              "  'see_also': ['hadoop', 'apache-spark'],\n",
              "  'tags': ['ibm', 'big-data'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Big Data Tools'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'hive',\n",
              "  'term': 'Apache Hive',\n",
              "  'definition': 'SQL-on-Hadoop data warehouse layer optimized for batch/long scans; unsuitable for low-latency transactions.\\n',\n",
              "  'examples': ['Ad-hoc aggregates on raw clickstream in HDFS'],\n",
              "  'see_also': ['hadoop', 'apache-spark'],\n",
              "  'tags': ['ibm', 'big-data', 'sql'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Big Data Tools'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'iiba',\n",
              "  'term': 'International Institute of Business Analysis (IIBA)',\n",
              "  'definition': 'A global non-profit association for business analysis that maintains standards (including the BABOK Guide) and offers certifications such as ECBA, CCBA, and CBAP.\\n',\n",
              "  'examples': ['Using ECBA/CCBA/CBAP levels to frame credentials on the Portfolio'],\n",
              "  'see_also': ['babok-guide', 'cbap-certification'],\n",
              "  'tags': ['cbap', 'credentials'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'json',\n",
              "  'term': 'JSON',\n",
              "  'definition': 'Lightweight text format for structured data (key/value, arrays); common for APIs/web services.\\n',\n",
              "  'examples': ['GTM → GA4 event payloads'],\n",
              "  'see_also': ['xml', 'semi-structured-data', 'nosql-database'],\n",
              "  'tags': ['ibm', 'formats'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – File Formats'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'need',\n",
              "  'term': 'Need',\n",
              "  'definition': 'A problem or opportunity that motivates Change; needs can trigger changes and new changes can introduce further needs (iterative cycle).\\n',\n",
              "  'examples': ['Low funnel visibility → add checkout events; later, need for attribution refinement'],\n",
              "  'see_also': ['change', 'solution', 'value', 'baccm'],\n",
              "  'tags': ['cbap', 'baccm'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 2'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'non-functional-requirements',\n",
              "  'term': 'Non-Functional Requirements (Quality Attributes)',\n",
              "  'definition': 'Conditions under which the solution must remain effective (e.g., security, performance, availability, accessibility, maintainability, recoverability, audit).\\n',\n",
              "  'examples': ['Handle 100 requests per minute without delayed response'],\n",
              "  'see_also': ['solution-requirements', 'solution-evaluation'],\n",
              "  'tags': ['cbap', 'quality'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'nosql-database',\n",
              "  'term': 'NoSQL Database',\n",
              "  'definition': 'Non-relational stores with flexible schemas; common models include key-value, document, column-family, and graph—optimized for scale/performance.\\n',\n",
              "  'examples': ['Document store for event payloads; key-value cache for sessions'],\n",
              "  'see_also': ['relational-database', 'data-lake'],\n",
              "  'tags': ['ibm', 'repositories'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Databases & Repositories'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'perspective',\n",
              "  'term': 'Perspective (BA Flavor)',\n",
              "  'definition': 'An organizational context or delivery approach (e.g., agile, process-centric, product-led) that shapes which techniques you use and how you apply BA tasks.\\n',\n",
              "  'examples': ['Adapting Trainer backlog practices for a startup vs. a risk-averse enterprise'],\n",
              "  'see_also': ['babok-knowledge-areas', 'underlying-competencies'],\n",
              "  'tags': ['cbap', 'approach'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'predictive-analytics',\n",
              "  'term': 'Predictive Analytics',\n",
              "  'definition': 'Uses historical patterns to estimate the likelihood of future outcomes; results are probabilistic.\\n',\n",
              "  'examples': ['Forecast weekly sessions from seasonal history'],\n",
              "  'see_also': ['time-series', 'data-scientist'],\n",
              "  'tags': ['ibm', 'analytics-types'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 1 – Analysis Types'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'prescriptive-analytics',\n",
              "  'term': 'Prescriptive Analytics',\n",
              "  'definition': 'Evaluates possible actions and their likely outcomes to recommend what to do next.\\n',\n",
              "  'examples': ['Choose promo variant that maximizes predicted conversions'],\n",
              "  'see_also': ['predictive-analytics', 'optimization'],\n",
              "  'tags': ['ibm', 'analytics-types'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 1 – Analysis Types'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'python',\n",
              "  'term': 'Python',\n",
              "  'definition': 'General-purpose language with rich analytics libraries (NumPy, pandas); readable syntax and strong community—common for data prep, ML, and ETL.\\n',\n",
              "  'examples': ['pandas transform for GA4 event features'],\n",
              "  'see_also': ['apache-spark', 'sql', 'r-language'],\n",
              "  'tags': ['ibm', 'languages'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 2 – Languages'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'r-language',\n",
              "  'term': 'R (Language)',\n",
              "  'definition': 'Open-source environment for statistics, visualization, and analysis; extensible ecosystem (ggplot2, plotly) and report/app publishing.\\n',\n",
              "  'examples': ['Exploratory plots for streak patterns'],\n",
              "  'see_also': ['python', 'sql'],\n",
              "  'tags': ['ibm', 'languages'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 2 – Languages'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'relational-database',\n",
              "  'term': 'Relational Database (RDBMS)',\n",
              "  'definition': 'Table-based store with defined schema and SQL querying; supports joins, integrity constraints, and ACID properties.\\n',\n",
              "  'examples': ['Dimensional model for reporting KPIs'],\n",
              "  'see_also': ['sql', 'nosql-database', 'data-warehouse'],\n",
              "  'tags': ['ibm', 'repositories'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Databases & Repositories'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'requirements-levels',\n",
              "  'term': 'Requirements Levels',\n",
              "  'definition': 'BABOK groups requirements into four levels: Business (why outcomes), Stakeholder (needs/expectations by actor), Solution (capabilities and qualities), and Transition (temporary needs to move from current to future state).\\n',\n",
              "  'examples': ['Mapping Trainer goals → user stories → acceptance criteria → rollout plan'],\n",
              "  'see_also': ['business-requirements',\n",
              "   'stakeholder-requirements',\n",
              "   'solution-requirements',\n",
              "   'transition-requirements'],\n",
              "  'tags': ['cbap', 'requirements'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'requirements-lifecycle-management',\n",
              "  'term': 'Requirements Life Cycle Management',\n",
              "  'definition': 'Planning, tracing, maintaining, prioritizing, and approving requirements from discovery through change, ensuring they remain current and aligned to value.\\n',\n",
              "  'examples': ['Trace GA4 events to stakeholder outcomes and update as scope changes'],\n",
              "  'see_also': ['requirements-levels', 'solution-requirements'],\n",
              "  'tags': ['cbap', 'requirements'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'semi-structured-data',\n",
              "  'term': 'Semi-Structured Data',\n",
              "  'definition': 'Data with organizational properties but no rigid schema; uses tags/metadata (e.g., XML/JSON) and is often hierarchical.\\n',\n",
              "  'examples': ['Webhook JSON payloads for events'],\n",
              "  'see_also': ['structured-data',\n",
              "   'unstructured-data',\n",
              "   'json',\n",
              "   'xml',\n",
              "   'nosql-database'],\n",
              "  'tags': ['ibm', 'data-types'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Data Types & Sources'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'solution',\n",
              "  'term': 'Solution',\n",
              "  'definition': 'A specific way to satisfy one or more Needs by resolving a problem or enabling an opportunity.\\n',\n",
              "  'examples': ['Deploy GTM container with standardized event schema'],\n",
              "  'see_also': ['need', 'value', 'stakeholder', 'baccm'],\n",
              "  'tags': ['cbap', 'baccm'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 2'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'solution-evaluation',\n",
              "  'term': 'Solution Evaluation',\n",
              "  'definition': 'Assessing a solution’s performance and value after or during delivery to verify it achieves the desired outcomes and to identify improvements.\\n',\n",
              "  'examples': ['Validate GA4 custom events deliver the engagement metrics promised'],\n",
              "  'see_also': ['business-requirements', 'non-functional-requirements'],\n",
              "  'tags': ['cbap', 'quality'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'solution-requirements',\n",
              "  'term': 'Solution Requirements',\n",
              "  'definition': 'Capabilities and qualities the solution must have to meet stakeholder needs; split into functional (behaviors/acceptance criteria) and non-functional (quality attributes and constraints).\\n',\n",
              "  'examples': ['Send reminder email when session expires and items remain in cart'],\n",
              "  'see_also': ['functional-requirements', 'non-functional-requirements'],\n",
              "  'tags': ['cbap', 'requirements'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'sql',\n",
              "  'term': 'SQL',\n",
              "  'definition': 'Standard query language for creating and manipulating relational data (tables, views, joins, DML/DDL, stored procedures).\\n',\n",
              "  'examples': ['Windowed KPI rollups in a warehouse'],\n",
              "  'see_also': ['relational-database', 'hive'],\n",
              "  'tags': ['ibm', 'languages'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics', 'module': 'Module 2 – Languages'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'stakeholder',\n",
              "  'term': 'Stakeholder',\n",
              "  'definition': 'Any person, group, or organization with a role in, interest in, or impact from a change. Stakeholders supply needs, consume outcomes, and collaborate to define value.\\n',\n",
              "  'examples': ['Data consumer for GA4 metrics (marketing analyst, product owner)'],\n",
              "  'see_also': ['elicitation', 'stakeholder-requirements'],\n",
              "  'tags': ['cbap'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'stakeholder-requirements',\n",
              "  'term': 'Stakeholder Requirements',\n",
              "  'definition': 'Needs and expectations of specific stakeholders or user groups, often expressed as user stories to clarify who needs what and why.\\n',\n",
              "  'examples': ['As a visitor, I want my cart retained so I can resume later'],\n",
              "  'see_also': ['business-requirements',\n",
              "   'solution-requirements',\n",
              "   'elicitation'],\n",
              "  'tags': ['cbap', 'requirements'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'strategy-analysis',\n",
              "  'term': 'Strategy Analysis',\n",
              "  'definition': 'Pre-project analysis to understand the current and future states, define business goals and scope, and select initiatives that deliver value.\\n',\n",
              "  'examples': ['Define objectives for The Trainer (ritual cadence, streak goals)'],\n",
              "  'see_also': ['business-requirements', 'solution-evaluation'],\n",
              "  'tags': ['cbap', 'planning'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'structured-data',\n",
              "  'term': 'Structured Data',\n",
              "  'definition': 'Data with a well-defined schema (rows/columns) that fits relational tables and standard analytical methods.\\n',\n",
              "  'examples': ['Survey response table; GA session table'],\n",
              "  'see_also': ['semi-structured-data',\n",
              "   'unstructured-data',\n",
              "   'relational-database'],\n",
              "  'tags': ['ibm', 'data-types'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Data Types & Sources'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'transition-requirements',\n",
              "  'term': 'Transition Requirements',\n",
              "  'definition': 'Temporary capabilities and conditions needed to move from current to future state, such as data migration, training, and phased releases.\\n',\n",
              "  'examples': ['Migrate historic events to new GA4 property; train contributors'],\n",
              "  'see_also': ['requirements-levels', 'solution-evaluation'],\n",
              "  'tags': ['cbap', 'delivery'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'underlying-competencies',\n",
              "  'term': 'Underlying Competencies',\n",
              "  'definition': 'Human skills and business knowledge that complement BA methods—communication, facilitation, critical thinking, domain awareness—enabling effective practice.\\n',\n",
              "  'examples': ['Facilitating a cross-module retro for The Trainer'],\n",
              "  'see_also': ['elicitation', 'perspective'],\n",
              "  'tags': ['cbap', 'skills'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 1 – Introduction'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'unstructured-data',\n",
              "  'term': 'Unstructured Data',\n",
              "  'definition': 'Data without a predefined format (text, images, audio/video, PDFs) that does not map cleanly to rows/columns.\\n',\n",
              "  'examples': ['Session recordings, support emails, screenshots'],\n",
              "  'see_also': ['semi-structured-data', 'data-lake', 'nosql-database'],\n",
              "  'tags': ['ibm', 'data-types'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – Data Types & Sources'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'value',\n",
              "  'term': 'Value',\n",
              "  'definition': 'The importance or usefulness of something to a Stakeholder; can be delivered by different Solutions and may be tangible (e.g., revenue, cost) or intangible (e.g., ease of use, brand loyalty).\\n',\n",
              "  'examples': ['Faster dashboard load → higher satisfaction (intangible); reduced churn (tangible)'],\n",
              "  'see_also': ['stakeholder', 'solution', 'need', 'baccm'],\n",
              "  'tags': ['cbap', 'baccm'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'CBAP', 'module': 'Module 2'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'xlsx',\n",
              "  'term': 'XLSX (Excel Workbook)',\n",
              "  'definition': 'Open XML spreadsheet format with multiple worksheets; tabular cells with formulas/formatting.\\n',\n",
              "  'examples': ['Manual backlog tracker with streak metrics'],\n",
              "  'see_also': ['delimited-text-file', 'data-wrangling'],\n",
              "  'tags': ['ibm', 'formats'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – File Formats'},\n",
              "  'status': 'draft'},\n",
              " {'key': 'xml',\n",
              "  'term': 'XML',\n",
              "  'definition': 'Tag-based markup for structured exchange; human/machine readable; platform/language independent.\\n',\n",
              "  'examples': ['Survey exports with hierarchical question blocks'],\n",
              "  'see_also': ['json', 'semi-structured-data'],\n",
              "  'tags': ['ibm', 'formats'],\n",
              "  'orbit': 'Delivery & Insight',\n",
              "  'source': {'course': 'IBM Data Analytics',\n",
              "   'module': 'Module 2 – File Formats'},\n",
              "  'status': 'draft'}]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml, collections, itertools\n",
        "\n",
        "OUT_PATH = \"/content/drive/MyDrive/FourTwentyAnalytics/modules/trainer-model/seeds/glossary.yml\"  # adjust if needed\n",
        "\n",
        "with open(OUT_PATH, encoding=\"utf-8\") as f:\n",
        "    items = yaml.safe_load(f) or []\n",
        "\n",
        "keys = [it[\"key\"] for it in items]\n",
        "dupes = [k for k, c in collections.Counter(keys).items() if c > 1]\n",
        "missing_core = [it.get(\"key\") for it in items\n",
        "                if not {\"key\",\"term\",\"definition\"} <= set(it)]\n",
        "\n",
        "print(f\"items={len(items)} unique_keys={len(set(keys))} deduped={len(keys)-len(set(keys))}\")\n",
        "print(\"duplicate_keys:\", dupes)\n",
        "print(\"missing_core_fields:\", missing_core[:10])\n",
        "\n",
        "# optional spot checks – change keys as you like\n",
        "def get(k):\n",
        "    return next((i for i in items if i[\"key\"] == k), None)\n",
        "\n",
        "for k in [\"baccm\", \"data_ecosystem\"]:\n",
        "    it = get(k)\n",
        "    if it:\n",
        "        print(f\"\\n[{k}] see_also →\", it.get(\"see_also\"))\n",
        "        print(f\"[{k}] tags     →\", it.get(\"tags\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_yuFeUhNybf",
        "outputId": "3e74f8df-a7a5-4609-818c-fa0d0e289a4f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "items=64 unique_keys=64 deduped=0\n",
            "duplicate_keys: []\n",
            "missing_core_fields: []\n",
            "\n",
            "[baccm] see_also → ['change', 'need', 'solution', 'stakeholder', 'value', 'context', 'babok-guide']\n",
            "[baccm] tags     → ['cbap', 'framework']\n"
          ]
        }
      ]
    }
  ]
}